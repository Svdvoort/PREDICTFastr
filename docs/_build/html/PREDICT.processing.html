<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>PREDICT.processing package &#8212; PREDICT 2.1.1 documentation</title>
    
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '2.1.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="predict-processing-package">
<h1>PREDICT.processing package<a class="headerlink" href="#predict-processing-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-PREDICT.processing.AdvancedSampler">
<span id="predict-processing-advancedsampler-module"></span><h2>PREDICT.processing.AdvancedSampler module<a class="headerlink" href="#module-PREDICT.processing.AdvancedSampler" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="PREDICT.processing.AdvancedSampler.AdvancedSampler">
<em class="property">class </em><code class="descclassname">PREDICT.processing.AdvancedSampler.</code><code class="descname">AdvancedSampler</code><span class="sig-paren">(</span><em>param_distributions</em>, <em>n_iter</em>, <em>random_state=None</em>, <em>method='Halton'</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.AdvancedSampler.AdvancedSampler" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Generator on parameters sampled from given distributions using
numerical sequences. Based on the sklearn ParameterSampler.</p>
<p>Non-deterministic iterable over random candidate combinations for hyper-
parameter search. If all parameters are presented as a list,
sampling without replacement is performed. If at least one parameter
is given as a distribution, sampling with replacement is used.
It is highly recommended to use continuous distributions for continuous
parameters.</p>
<p>Note that before SciPy 0.16, the <code class="docutils literal"><span class="pre">scipy.stats.distributions</span></code> do not
accept a custom RNG instance and always use the singleton RNG from
<code class="docutils literal"><span class="pre">numpy.random</span></code>. Hence setting <code class="docutils literal"><span class="pre">random_state</span></code> will not guarantee a
deterministic iteration whenever <code class="docutils literal"><span class="pre">scipy.stats</span></code> distributions are used to
define the parameter search space. Deterministic behavior is however
guaranteed from SciPy 0.16 onwards.</p>
<p>Read more in the <a class="reference internal" href="search.html"><span class="std std-ref">User Guide</span></a>.</p>
<dl class="docutils">
<dt>param_distributions <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd>Dictionary where the keys are parameters and values
are distributions from which a parameter is to be sampled.
Distributions either have to provide a <code class="docutils literal"><span class="pre">rvs</span></code> function
to sample from them, or can be given as a list of values,
where a uniform distribution is assumed.</dd>
<dt>n_iter <span class="classifier-delimiter">:</span> <span class="classifier">integer</span></dt>
<dd>Number of parameter settings that are produced.</dd>
<dt>random_state <span class="classifier-delimiter">:</span> <span class="classifier">int or RandomState</span></dt>
<dd>Pseudo random number generator state used for random uniform sampling
from lists of possible values instead of scipy.stats distributions.</dd>
</dl>
<dl class="docutils">
<dt>params <span class="classifier-delimiter">:</span> <span class="classifier">dict of string to any</span></dt>
<dd><strong>Yields</strong> dictionaries mapping each estimator parameter to
as sampled value.</dd>
</dl>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">PREDICT.processing.HaltonSampler</span> <span class="k">import</span> <span class="n">HaltonSampler</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">scipy.stats.distributions</span> <span class="k">import</span> <span class="n">expon</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;a&#39;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="n">expon</span><span class="p">()}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">HaltonSampler</span><span class="p">(</span><span class="n">param_grid</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">4</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rounded_list</span> <span class="o">=</span> <span class="p">[</span><span class="nb">dict</span><span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span> <span class="k">for</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="ow">in</span> <span class="n">d</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
<span class="gp">... </span>                <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">param_list</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rounded_list</span> <span class="o">==</span> <span class="p">[{</span><span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="mf">0.89856</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span>
<span class="gp">... </span>                 <span class="p">{</span><span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="mf">0.923223</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span>
<span class="gp">... </span>                 <span class="p">{</span><span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="mf">1.878964</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">},</span>
<span class="gp">... </span>                 <span class="p">{</span><span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="mf">1.038159</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}]</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="PREDICT.processing.AdvancedSampler.exp_uniform">
<em class="property">class </em><code class="descclassname">PREDICT.processing.AdvancedSampler.</code><code class="descname">exp_uniform</code><span class="sig-paren">(</span><em>loc=-1</em>, <em>scale=0</em>, <em>base=2.718281828459045</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.AdvancedSampler.exp_uniform" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="PREDICT.processing.AdvancedSampler.exp_uniform.rvs">
<code class="descname">rvs</code><span class="sig-paren">(</span><em>size=None</em>, <em>random_state=None</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.AdvancedSampler.exp_uniform.rvs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="PREDICT.processing.AdvancedSampler.log_uniform">
<em class="property">class </em><code class="descclassname">PREDICT.processing.AdvancedSampler.</code><code class="descname">log_uniform</code><span class="sig-paren">(</span><em>loc=-1</em>, <em>scale=0</em>, <em>base=10</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.AdvancedSampler.log_uniform" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="PREDICT.processing.AdvancedSampler.log_uniform.rvs">
<code class="descname">rvs</code><span class="sig-paren">(</span><em>size=None</em>, <em>random_state=None</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.AdvancedSampler.log_uniform.rvs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-PREDICT.processing.ICC">
<span id="predict-processing-icc-module"></span><h2>PREDICT.processing.ICC module<a class="headerlink" href="#module-PREDICT.processing.ICC" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="PREDICT.processing.ICC.ICC">
<code class="descclassname">PREDICT.processing.ICC.</code><code class="descname">ICC</code><span class="sig-paren">(</span><em>M</em>, <em>ICCtype='inter'</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.ICC.ICC" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Input:</dt>
<dd>M is matrix of observations. Rows: patients, columns: observers.
type: ICC type, currently &#8220;inter&#8221; or &#8220;intra&#8221;.</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="PREDICT.processing.ICC.ICC_anova">
<code class="descclassname">PREDICT.processing.ICC.</code><code class="descname">ICC_anova</code><span class="sig-paren">(</span><em>Y</em>, <em>ICCtype='inter'</em>, <em>more=False</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.ICC.ICC_anova" title="Permalink to this definition">¶</a></dt>
<dd><p>Adopted from Nipype with a slight alteration to distinguish inter and intra.
the data Y are entered as a &#8216;table&#8217; ie subjects are in rows and repeated
measures in columns
One Sample Repeated measure ANOVA
Y = XB + E with X = [FaTor / Subjects]</p>
</dd></dl>

</div>
<div class="section" id="module-PREDICT.processing.Imputer">
<span id="predict-processing-imputer-module"></span><h2>PREDICT.processing.Imputer module<a class="headerlink" href="#module-PREDICT.processing.Imputer" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-PREDICT.processing.SearchCV">
<span id="predict-processing-searchcv-module"></span><h2>PREDICT.processing.SearchCV module<a class="headerlink" href="#module-PREDICT.processing.SearchCV" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="PREDICT.processing.SearchCV.BaseSearchCV">
<em class="property">class </em><code class="descclassname">PREDICT.processing.SearchCV.</code><code class="descname">BaseSearchCV</code><span class="sig-paren">(</span><em>estimator</em>, <em>param_distributions={}</em>, <em>n_iter=10</em>, <em>scoring=None</em>, <em>fit_params=None</em>, <em>n_jobs=1</em>, <em>iid=True</em>, <em>refit=True</em>, <em>cv=None</em>, <em>verbose=0</em>, <em>pre_dispatch='2*n_jobs'</em>, <em>random_state=None</em>, <em>error_score='raise'</em>, <em>return_train_score=True</em>, <em>n_jobspercore=100</em>, <em>maxlen=100</em>, <em>fastr_plugin=None</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.BaseSearchCV" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">abc.NewBase</span></code></p>
<p>Base class for hyper parameter search with cross-validation.</p>
<dl class="attribute">
<dt id="PREDICT.processing.SearchCV.BaseSearchCV.best_params_">
<code class="descname">best_params_</code><a class="headerlink" href="#PREDICT.processing.SearchCV.BaseSearchCV.best_params_" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="PREDICT.processing.SearchCV.BaseSearchCV.best_score_">
<code class="descname">best_score_</code><a class="headerlink" href="#PREDICT.processing.SearchCV.BaseSearchCV.best_score_" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="PREDICT.processing.SearchCV.BaseSearchCV.create_ensemble">
<code class="descname">create_ensemble</code><span class="sig-paren">(</span><em>X_train</em>, <em>Y_train</em>, <em>verbose=None</em>, <em>initialize=True</em>, <em>scoring=None</em>, <em>method=50</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.BaseSearchCV.create_ensemble" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an (optimal) ensemble of a combination of hyperparameter settings
and the associated groupsels, PCAs, estimators etc.</p>
<p>Based on Caruana et al. 2004, but a little different:</p>
<ol class="arabic simple">
<li>Recreate the training/validation splits for a n-fold cross validation.</li>
<li><dl class="first docutils">
<dt>For each fold:</dt>
<dd><ol class="first last loweralpha">
<li>Start with an empty ensemble</li>
<li>Create starting ensemble by adding N individually best performing
models on the validation set. N is tuned on the validation set.</li>
<li>Add model that improves ensemble performance on validation set the most, with replacement.</li>
<li>Repeat (c) untill performance does not increase</li>
</ol>
</dd>
</dl>
</li>
</ol>
<p>The performance metric is the same as for the original hyperparameter
search, i.e. probably the F1-score for classification and r2-score
for regression. However, we recommend using the SAR score, as this is
more universal.</p>
<p>Method: top50 or Caruana</p>
</dd></dl>

<dl class="method">
<dt id="PREDICT.processing.SearchCV.BaseSearchCV.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.BaseSearchCV.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Call decision_function on the estimator with the best found parameters.</p>
<p>Only available if <code class="docutils literal"><span class="pre">refit=True</span></code> and the underlying estimator supports
<code class="docutils literal"><span class="pre">decision_function</span></code>.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">indexable, length n_samples</span></dt>
<dd>Must fulfill the input assumptions of the
underlying estimator.</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="PREDICT.processing.SearchCV.BaseSearchCV.grid_scores_">
<code class="descname">grid_scores_</code><a class="headerlink" href="#PREDICT.processing.SearchCV.BaseSearchCV.grid_scores_" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="PREDICT.processing.SearchCV.BaseSearchCV.inverse_transform">
<code class="descname">inverse_transform</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.BaseSearchCV.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Call inverse_transform on the estimator with the best found params.</p>
<p>Only available if the underlying estimator implements
<code class="docutils literal"><span class="pre">inverse_transform</span></code> and <code class="docutils literal"><span class="pre">refit=True</span></code>.</p>
<dl class="docutils">
<dt>Xt <span class="classifier-delimiter">:</span> <span class="classifier">indexable, length n_samples</span></dt>
<dd>Must fulfill the input assumptions of the
underlying estimator.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="PREDICT.processing.SearchCV.BaseSearchCV.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.BaseSearchCV.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Call predict on the estimator with the best found parameters.</p>
<p>Only available if <code class="docutils literal"><span class="pre">refit=True</span></code> and the underlying estimator supports
<code class="docutils literal"><span class="pre">predict</span></code>.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">indexable, length n_samples</span></dt>
<dd>Must fulfill the input assumptions of the
underlying estimator.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="PREDICT.processing.SearchCV.BaseSearchCV.predict_log_proba">
<code class="descname">predict_log_proba</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.BaseSearchCV.predict_log_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Call predict_log_proba on the estimator with the best found parameters.</p>
<p>Only available if <code class="docutils literal"><span class="pre">refit=True</span></code> and the underlying estimator supports
<code class="docutils literal"><span class="pre">predict_log_proba</span></code>.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">indexable, length n_samples</span></dt>
<dd>Must fulfill the input assumptions of the
underlying estimator.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="PREDICT.processing.SearchCV.BaseSearchCV.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.BaseSearchCV.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Call predict_proba on the estimator with the best found parameters.</p>
<p>Only available if <code class="docutils literal"><span class="pre">refit=True</span></code> and the underlying estimator supports
<code class="docutils literal"><span class="pre">predict_proba</span></code>.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">indexable, length n_samples</span></dt>
<dd>Must fulfill the input assumptions of the
underlying estimator.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="PREDICT.processing.SearchCV.BaseSearchCV.preprocess">
<code class="descname">preprocess</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.BaseSearchCV.preprocess" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply the available preprocssing methods to the features</p>
</dd></dl>

<dl class="method">
<dt id="PREDICT.processing.SearchCV.BaseSearchCV.process_fit">
<code class="descname">process_fit</code><span class="sig-paren">(</span><em>n_splits</em>, <em>parameters_est</em>, <em>parameters_all</em>, <em>test_sample_counts</em>, <em>test_scores</em>, <em>train_scores</em>, <em>fit_time</em>, <em>score_time</em>, <em>cv_iter</em>, <em>base_estimator</em>, <em>X</em>, <em>y</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.BaseSearchCV.process_fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Process the outcomes of a SearchCV fit and find the best settings
over all cross validations from all hyperparameters tested</p>
</dd></dl>

<dl class="method">
<dt id="PREDICT.processing.SearchCV.BaseSearchCV.refit_and_score">
<code class="descname">refit_and_score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>parameters_all</em>, <em>parameters_est</em>, <em>train</em>, <em>test</em>, <em>verbose=None</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.BaseSearchCV.refit_and_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Refit the base estimator and attributes such as GroupSel</p>
<dl class="docutils">
<dt>X: array, mandatory</dt>
<dd>Array containingfor each object (rows) the feature values
(1st Column) and the associated feature label (2nd Column).</dd>
<dt>y: list(?), mandatory</dt>
<dd>List containing the labels of the objects.</dd>
<dt>parameters_all: dictionary, mandatory</dt>
<dd>Contains the settings used for the all preprocessing functions
and the fitting. TODO: Create a default object and show the
fields.</dd>
<dt>parameters_est: dictionary, mandatory</dt>
<dd>Contains the settings used for the base estimator</dd>
<dt>train: list, mandatory</dt>
<dd>Indices of the objects to be used as training set.</dd>
<dt>test: list, mandatory</dt>
<dd>Indices of the objects to be used as testing set.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="PREDICT.processing.SearchCV.BaseSearchCV.score">
<code class="descname">score</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.BaseSearchCV.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the score on the given data, if the estimator has been refit.</p>
<p>This uses the score defined by <code class="docutils literal"><span class="pre">scoring</span></code> where provided, and the
<code class="docutils literal"><span class="pre">best_estimator_.score</span></code> method otherwise.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples, n_features]</span></dt>
<dd>Input data, where n_samples is the number of samples and
n_features is the number of features.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples] or [n_samples, n_output], optional</span></dt>
<dd>Target relative to X for classification or regression;
None for unsupervised learning.</dd>
</dl>
<p>score : float</p>
</dd></dl>

<dl class="method">
<dt id="PREDICT.processing.SearchCV.BaseSearchCV.transform">
<code class="descname">transform</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.BaseSearchCV.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Call transform on the estimator with the best found parameters.</p>
<p>Only available if the underlying estimator supports <code class="docutils literal"><span class="pre">transform</span></code> and
<code class="docutils literal"><span class="pre">refit=True</span></code>.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">indexable, length n_samples</span></dt>
<dd>Must fulfill the input assumptions of the
underlying estimator.</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="PREDICT.processing.SearchCV.BaseSearchCVJoblib">
<em class="property">class </em><code class="descclassname">PREDICT.processing.SearchCV.</code><code class="descname">BaseSearchCVJoblib</code><span class="sig-paren">(</span><em>estimator</em>, <em>param_distributions={}</em>, <em>n_iter=10</em>, <em>scoring=None</em>, <em>fit_params=None</em>, <em>n_jobs=1</em>, <em>iid=True</em>, <em>refit=True</em>, <em>cv=None</em>, <em>verbose=0</em>, <em>pre_dispatch='2*n_jobs'</em>, <em>random_state=None</em>, <em>error_score='raise'</em>, <em>return_train_score=True</em>, <em>n_jobspercore=100</em>, <em>maxlen=100</em>, <em>fastr_plugin=None</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.BaseSearchCVJoblib" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#PREDICT.processing.SearchCV.BaseSearchCV" title="PREDICT.processing.SearchCV.BaseSearchCV"><code class="xref py py-class docutils literal"><span class="pre">PREDICT.processing.SearchCV.BaseSearchCV</span></code></a></p>
<p>Base class for hyper parameter search with cross-validation.</p>
</dd></dl>

<dl class="class">
<dt id="PREDICT.processing.SearchCV.BaseSearchCVfastr">
<em class="property">class </em><code class="descclassname">PREDICT.processing.SearchCV.</code><code class="descname">BaseSearchCVfastr</code><span class="sig-paren">(</span><em>estimator</em>, <em>param_distributions={}</em>, <em>n_iter=10</em>, <em>scoring=None</em>, <em>fit_params=None</em>, <em>n_jobs=1</em>, <em>iid=True</em>, <em>refit=True</em>, <em>cv=None</em>, <em>verbose=0</em>, <em>pre_dispatch='2*n_jobs'</em>, <em>random_state=None</em>, <em>error_score='raise'</em>, <em>return_train_score=True</em>, <em>n_jobspercore=100</em>, <em>maxlen=100</em>, <em>fastr_plugin=None</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.BaseSearchCVfastr" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#PREDICT.processing.SearchCV.BaseSearchCV" title="PREDICT.processing.SearchCV.BaseSearchCV"><code class="xref py py-class docutils literal"><span class="pre">PREDICT.processing.SearchCV.BaseSearchCV</span></code></a></p>
<p>Base class for hyper parameter search with cross-validation.</p>
</dd></dl>

<dl class="class">
<dt id="PREDICT.processing.SearchCV.Ensemble">
<em class="property">class </em><code class="descclassname">PREDICT.processing.SearchCV.</code><code class="descname">Ensemble</code><span class="sig-paren">(</span><em>estimators</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.Ensemble" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">abc.NewBase</span></code></p>
<p>Ensemble of BaseSearchCV Estimators.</p>
<dl class="method">
<dt id="PREDICT.processing.SearchCV.Ensemble.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.Ensemble.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Call decision_function on the estimator with the best found parameters.</p>
<p>Only available if <code class="docutils literal"><span class="pre">refit=True</span></code> and the underlying estimator supports
<code class="docutils literal"><span class="pre">decision_function</span></code>.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">indexable, length n_samples</span></dt>
<dd>Must fulfill the input assumptions of the
underlying estimator.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="PREDICT.processing.SearchCV.Ensemble.inverse_transform">
<code class="descname">inverse_transform</code><span class="sig-paren">(</span><em>Xt</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.Ensemble.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Call inverse_transform on the estimator with the best found params.</p>
<p>Only available if the underlying estimator implements
<code class="docutils literal"><span class="pre">inverse_transform</span></code> and <code class="docutils literal"><span class="pre">refit=True</span></code>.</p>
<dl class="docutils">
<dt>Xt <span class="classifier-delimiter">:</span> <span class="classifier">indexable, length n_samples</span></dt>
<dd>Must fulfill the input assumptions of the
underlying estimator.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="PREDICT.processing.SearchCV.Ensemble.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.Ensemble.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Call predict on the estimator with the best found parameters.</p>
<p>Only available if <code class="docutils literal"><span class="pre">refit=True</span></code> and the underlying estimator supports
<code class="docutils literal"><span class="pre">predict</span></code>.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">indexable, length n_samples</span></dt>
<dd>Must fulfill the input assumptions of the
underlying estimator.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="PREDICT.processing.SearchCV.Ensemble.predict_log_proba">
<code class="descname">predict_log_proba</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.Ensemble.predict_log_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Call predict_log_proba on the estimator with the best found parameters.</p>
<p>Only available if <code class="docutils literal"><span class="pre">refit=True</span></code> and the underlying estimator supports
<code class="docutils literal"><span class="pre">predict_log_proba</span></code>.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">indexable, length n_samples</span></dt>
<dd>Must fulfill the input assumptions of the
underlying estimator.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="PREDICT.processing.SearchCV.Ensemble.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.Ensemble.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Call predict_proba on the estimator with the best found parameters.</p>
<p>Only available if <code class="docutils literal"><span class="pre">refit=True</span></code> and the underlying estimator supports
<code class="docutils literal"><span class="pre">predict_proba</span></code>.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">indexable, length n_samples</span></dt>
<dd>Must fulfill the input assumptions of the
underlying estimator.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="PREDICT.processing.SearchCV.Ensemble.transform">
<code class="descname">transform</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.Ensemble.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Call transform on the estimator with the best found parameters.</p>
<p>Only available if the underlying estimator supports <code class="docutils literal"><span class="pre">transform</span></code> and
<code class="docutils literal"><span class="pre">refit=True</span></code>.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">indexable, length n_samples</span></dt>
<dd>Must fulfill the input assumptions of the
underlying estimator.</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="PREDICT.processing.SearchCV.GridSearchCVJoblib">
<em class="property">class </em><code class="descclassname">PREDICT.processing.SearchCV.</code><code class="descname">GridSearchCVJoblib</code><span class="sig-paren">(</span><em>estimator</em>, <em>param_grid</em>, <em>scoring=None</em>, <em>fit_params=None</em>, <em>n_jobs=1</em>, <em>iid=True</em>, <em>refit=True</em>, <em>cv=None</em>, <em>verbose=0</em>, <em>pre_dispatch='2*n_jobs'</em>, <em>error_score='raise'</em>, <em>return_train_score=True</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.GridSearchCVJoblib" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#PREDICT.processing.SearchCV.BaseSearchCVJoblib" title="PREDICT.processing.SearchCV.BaseSearchCVJoblib"><code class="xref py py-class docutils literal"><span class="pre">PREDICT.processing.SearchCV.BaseSearchCVJoblib</span></code></a></p>
<p>Exhaustive search over specified parameter values for an estimator.</p>
<p>Important members are fit, predict.</p>
<p>GridSearchCV implements a &#8220;fit&#8221; and a &#8220;score&#8221; method.
It also implements &#8220;predict&#8221;, &#8220;predict_proba&#8221;, &#8220;decision_function&#8221;,
&#8220;transform&#8221; and &#8220;inverse_transform&#8221; if they are implemented in the
estimator used.</p>
<p>The parameters of the estimator used to apply these methods are optimized
by cross-validated grid-search over a parameter grid.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="docutils">
<dt>estimator <span class="classifier-delimiter">:</span> <span class="classifier">estimator object.</span></dt>
<dd>This is assumed to implement the scikit-learn estimator interface.
Either estimator needs to provide a <code class="docutils literal"><span class="pre">score</span></code> function,
or <code class="docutils literal"><span class="pre">scoring</span></code> must be passed.</dd>
<dt>param_grid <span class="classifier-delimiter">:</span> <span class="classifier">dict or list of dictionaries</span></dt>
<dd>Dictionary with parameters names (string) as keys and lists of
parameter settings to try as values, or a list of such
dictionaries, in which case the grids spanned by each dictionary
in the list are explored. This enables searching over any sequence
of parameter settings.</dd>
<dt>scoring <span class="classifier-delimiter">:</span> <span class="classifier">string, callable or None, default=None</span></dt>
<dd>A string (see model evaluation documentation) or
a scorer callable object / function with signature
<code class="docutils literal"><span class="pre">scorer(estimator,</span> <span class="pre">X,</span> <span class="pre">y)</span></code>.
If <code class="docutils literal"><span class="pre">None</span></code>, the <code class="docutils literal"><span class="pre">score</span></code> method of the estimator is used.</dd>
<dt>fit_params <span class="classifier-delimiter">:</span> <span class="classifier">dict, optional</span></dt>
<dd>Parameters to pass to the fit method.</dd>
<dt>n_jobs <span class="classifier-delimiter">:</span> <span class="classifier">int, default=1</span></dt>
<dd>Number of jobs to run in parallel.</dd>
<dt>pre_dispatch <span class="classifier-delimiter">:</span> <span class="classifier">int, or string, optional</span></dt>
<dd><p class="first">Controls the number of jobs that get dispatched during parallel
execution. Reducing this number can be useful to avoid an
explosion of memory consumption when more jobs get dispatched
than CPUs can process. This parameter can be:</p>
<blockquote class="last">
<div><ul class="simple">
<li>None, in which case all the jobs are immediately
created and spawned. Use this for lightweight and
fast-running jobs, to avoid delays due to on-demand
spawning of the jobs</li>
<li>An int, giving the exact number of total jobs that are
spawned</li>
<li>A string, giving an expression as a function of n_jobs,
as in &#8216;2*n_jobs&#8217;</li>
</ul>
</div></blockquote>
</dd>
<dt>iid <span class="classifier-delimiter">:</span> <span class="classifier">boolean, default=True</span></dt>
<dd>If True, the data is assumed to be identically distributed across
the folds, and the loss minimized is the total loss per sample,
and not the mean loss across the folds.</dd>
<dt>cv <span class="classifier-delimiter">:</span> <span class="classifier">int, cross-validation generator or an iterable, optional</span></dt>
<dd><p class="first">Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<blockquote>
<div><ul class="simple">
<li>None, to use the default 3-fold cross validation,</li>
<li>integer, to specify the number of folds in a <cite>(Stratified)KFold</cite>,</li>
<li>An object to be used as a cross-validation generator.</li>
<li>An iterable yielding train, test splits.</li>
</ul>
</div></blockquote>
<p>For integer/None inputs, if the estimator is a classifier and <code class="docutils literal"><span class="pre">y</span></code> is
either binary or multiclass, <code class="xref py py-class docutils literal"><span class="pre">StratifiedKFold</span></code> is used. In all
other cases, <code class="xref py py-class docutils literal"><span class="pre">KFold</span></code> is used.</p>
<p class="last">Refer <span class="xref std std-ref">User Guide</span> for the various
cross-validation strategies that can be used here.</p>
</dd>
<dt>refit <span class="classifier-delimiter">:</span> <span class="classifier">boolean, default=True</span></dt>
<dd>Refit the best estimator with the entire dataset.
If &#8220;False&#8221;, it is impossible to make predictions using
this GridSearchCV instance after fitting.</dd>
<dt>verbose <span class="classifier-delimiter">:</span> <span class="classifier">integer</span></dt>
<dd>Controls the verbosity: the higher, the more messages.</dd>
<dt>error_score <span class="classifier-delimiter">:</span> <span class="classifier">&#8216;raise&#8217; (default) or numeric</span></dt>
<dd>Value to assign to the score if an error occurs in estimator fitting.
If set to &#8216;raise&#8217;, the error is raised. If a numeric value is given,
FitFailedWarning is raised. This parameter does not affect the refit
step, which will always raise the error.</dd>
<dt>return_train_score <span class="classifier-delimiter">:</span> <span class="classifier">boolean, default=True</span></dt>
<dd>If <code class="docutils literal"><span class="pre">'False'</span></code>, the <code class="docutils literal"><span class="pre">cv_results_</span></code> attribute will not include training
scores.</dd>
</dl>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">svm</span><span class="p">,</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">GridSearchCV</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:(</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">),</span> <span class="s1">&#39;C&#39;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">svr</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">svr</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="gp">... </span>                            
<span class="go">GridSearchCV(cv=None, error_score=...,</span>
<span class="go">       estimator=SVC(C=1.0, cache_size=..., class_weight=..., coef0=...,</span>
<span class="go">                     decision_function_shape=None, degree=..., gamma=...,</span>
<span class="go">                     kernel=&#39;rbf&#39;, max_iter=-1, probability=False,</span>
<span class="go">                     random_state=None, shrinking=True, tol=...,</span>
<span class="go">                     verbose=False),</span>
<span class="go">       fit_params={}, iid=..., n_jobs=1,</span>
<span class="go">       param_grid=..., pre_dispatch=..., refit=..., return_train_score=...,</span>
<span class="go">       scoring=..., verbose=...)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">sorted</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">cv_results_</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="gp">... </span>                            
<span class="go">[&#39;mean_fit_time&#39;, &#39;mean_score_time&#39;, &#39;mean_test_score&#39;,...</span>
<span class="go"> &#39;mean_train_score&#39;, &#39;param_C&#39;, &#39;param_kernel&#39;, &#39;params&#39;,...</span>
<span class="go"> &#39;rank_test_score&#39;, &#39;split0_test_score&#39;,...</span>
<span class="go"> &#39;split0_train_score&#39;, &#39;split1_test_score&#39;, &#39;split1_train_score&#39;,...</span>
<span class="go"> &#39;split2_test_score&#39;, &#39;split2_train_score&#39;,...</span>
<span class="go"> &#39;std_fit_time&#39;, &#39;std_score_time&#39;, &#39;std_test_score&#39;, &#39;std_train_score&#39;...]</span>
</pre></div>
</div>
<dl class="docutils">
<dt><a href="#id1"><span class="problematic" id="id2">cv_results_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">dict of numpy (masked) ndarrays</span></dt>
<dd><p class="first">A dict with keys as column headers and values as columns, that can be
imported into a pandas <code class="docutils literal"><span class="pre">DataFrame</span></code>.</p>
<p>For instance the below given table</p>
<table border="1" class="docutils">
<colgroup>
<col width="19%" />
<col width="17%" />
<col width="19%" />
<col width="27%" />
<col width="5%" />
<col width="14%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">param_kernel</th>
<th class="head">param_gamma</th>
<th class="head">param_degree</th>
<th class="head">split0_test_score</th>
<th class="head">...</th>
<th class="head"><a href="#id3"><span class="problematic" id="id4">rank_</span></a>....</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>&#8216;poly&#8217;</td>
<td>&#8211;</td>
<td>2</td>
<td>0.8</td>
<td>...</td>
<td>2</td>
</tr>
<tr class="row-odd"><td>&#8216;poly&#8217;</td>
<td>&#8211;</td>
<td>3</td>
<td>0.7</td>
<td>...</td>
<td>4</td>
</tr>
<tr class="row-even"><td>&#8216;rbf&#8217;</td>
<td>0.1</td>
<td>&#8211;</td>
<td>0.8</td>
<td>...</td>
<td>3</td>
</tr>
<tr class="row-odd"><td>&#8216;rbf&#8217;</td>
<td>0.2</td>
<td>&#8211;</td>
<td>0.9</td>
<td>...</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>will be represented by a <code class="docutils literal"><span class="pre">cv_results_</span></code> dict of:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="s1">&#39;param_kernel&#39;</span><span class="p">:</span> <span class="n">masked_array</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">],</span>
                             <span class="n">mask</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span> <span class="kc">False</span> <span class="kc">False</span> <span class="kc">False</span><span class="p">]</span><span class="o">...</span><span class="p">)</span>
<span class="s1">&#39;param_gamma&#39;</span><span class="p">:</span> <span class="n">masked_array</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="o">--</span> <span class="o">--</span> <span class="mf">0.1</span> <span class="mf">0.2</span><span class="p">],</span>
                            <span class="n">mask</span> <span class="o">=</span> <span class="p">[</span> <span class="kc">True</span>  <span class="kc">True</span> <span class="kc">False</span> <span class="kc">False</span><span class="p">]</span><span class="o">...</span><span class="p">),</span>
<span class="s1">&#39;param_degree&#39;</span><span class="p">:</span> <span class="n">masked_array</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.0</span> <span class="mf">3.0</span> <span class="o">--</span> <span class="o">--</span><span class="p">],</span>
                             <span class="n">mask</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span> <span class="kc">False</span>  <span class="kc">True</span>  <span class="kc">True</span><span class="p">]</span><span class="o">...</span><span class="p">),</span>
<span class="s1">&#39;split0_test_score&#39;</span>  <span class="p">:</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span>
<span class="s1">&#39;split1_test_score&#39;</span>  <span class="p">:</span> <span class="p">[</span><span class="mf">0.82</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.78</span><span class="p">],</span>
<span class="s1">&#39;mean_test_score&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mf">0.81</span><span class="p">,</span> <span class="mf">0.60</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.82</span><span class="p">],</span>
<span class="s1">&#39;std_test_score&#39;</span>     <span class="p">:</span> <span class="p">[</span><span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">],</span>
<span class="s1">&#39;rank_test_score&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="s1">&#39;split0_train_score&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span>
<span class="s1">&#39;split1_train_score&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.82</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span>
<span class="s1">&#39;mean_train_score&#39;</span>   <span class="p">:</span> <span class="p">[</span><span class="mf">0.81</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span>
<span class="s1">&#39;std_train_score&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">],</span>
<span class="s1">&#39;mean_fit_time&#39;</span>      <span class="p">:</span> <span class="p">[</span><span class="mf">0.73</span><span class="p">,</span> <span class="mf">0.63</span><span class="p">,</span> <span class="mf">0.43</span><span class="p">,</span> <span class="mf">0.49</span><span class="p">],</span>
<span class="s1">&#39;std_fit_time&#39;</span>       <span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span>
<span class="s1">&#39;mean_score_time&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mf">0.007</span><span class="p">,</span> <span class="mf">0.06</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">],</span>
<span class="s1">&#39;std_score_time&#39;</span>     <span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.002</span><span class="p">,</span> <span class="mf">0.003</span><span class="p">,</span> <span class="mf">0.005</span><span class="p">],</span>
<span class="s1">&#39;params&#39;</span>             <span class="p">:</span> <span class="p">[{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="s1">&#39;degree&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">},</span> <span class="o">...</span><span class="p">],</span>
<span class="p">}</span>
</pre></div>
</div>
<p>NOTE that the key <code class="docutils literal"><span class="pre">'params'</span></code> is used to store a list of parameter
settings dict for all the parameter candidates.</p>
<p class="last">The <code class="docutils literal"><span class="pre">mean_fit_time</span></code>, <code class="docutils literal"><span class="pre">std_fit_time</span></code>, <code class="docutils literal"><span class="pre">mean_score_time</span></code> and
<code class="docutils literal"><span class="pre">std_score_time</span></code> are all in seconds.</p>
</dd>
<dt><a href="#id5"><span class="problematic" id="id6">best_estimator_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">estimator</span></dt>
<dd>Estimator that was chosen by the search, i.e. estimator
which gave highest score (or smallest loss if specified)
on the left out data. Not available if refit=False.</dd>
<dt><a href="#id7"><span class="problematic" id="id8">best_score_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Score of best_estimator on the left out data.</dd>
<dt><a href="#id9"><span class="problematic" id="id10">best_params_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd>Parameter setting that gave the best results on the hold out data.</dd>
<dt><a href="#id11"><span class="problematic" id="id12">best_index_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first">The index (of the <code class="docutils literal"><span class="pre">cv_results_</span></code> arrays) which corresponds to the best
candidate parameter setting.</p>
<p class="last">The dict at <code class="docutils literal"><span class="pre">search.cv_results_['params'][search.best_index_]</span></code> gives
the parameter setting for the best model, that gives the highest
mean score (<code class="docutils literal"><span class="pre">search.best_score_</span></code>).</p>
</dd>
<dt><a href="#id13"><span class="problematic" id="id14">scorer_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">function</span></dt>
<dd>Scorer function used on the held out data to choose the best
parameters for the model.</dd>
<dt><a href="#id15"><span class="problematic" id="id16">n_splits_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>The number of cross-validation splits (folds/iterations).</dd>
</dl>
<p>The parameters selected are those that maximize the score of the left out
data, unless an explicit score is passed in which case it is used instead.</p>
<p>If <cite>n_jobs</cite> was set to a value higher than one, the data is copied for each
point in the grid (and not <cite>n_jobs</cite> times). This is done for efficiency
reasons if individual jobs take very little time, but may raise errors if
the dataset is large and not enough memory is available.  A workaround in
this case is to set <cite>pre_dispatch</cite>. Then, the memory is copied only
<cite>pre_dispatch</cite> many times. A reasonable value for <cite>pre_dispatch</cite> is <cite>2 *
n_jobs</cite>.</p>
<dl class="docutils">
<dt><code class="xref py py-class docutils literal"><span class="pre">ParameterGrid</span></code>:</dt>
<dd>generates all the combinations of a hyperparameter grid.</dd>
<dt><code class="xref py py-func docutils literal"><span class="pre">sklearn.model_selection.train_test_split()</span></code>:</dt>
<dd>utility function to split the data into a development set usable
for fitting a GridSearchCV instance and an evaluation set for
its final evaluation.</dd>
<dt><code class="xref py py-func docutils literal"><span class="pre">sklearn.metrics.make_scorer()</span></code>:</dt>
<dd>Make a scorer from a performance metric or loss function.</dd>
</dl>
<dl class="method">
<dt id="PREDICT.processing.SearchCV.GridSearchCVJoblib.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em>, <em>groups=None</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.GridSearchCVJoblib.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Run fit with all sets of parameters.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples, n_features]</span></dt>
<dd>Training vector, where n_samples is the number of samples and
n_features is the number of features.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples] or [n_samples, n_output], optional</span></dt>
<dd>Target relative to X for classification or regression;
None for unsupervised learning.</dd>
<dt>groups <span class="classifier-delimiter">:</span> <span class="classifier">array-like, with shape (n_samples,), optional</span></dt>
<dd>Group labels for the samples used while splitting the dataset into
train/test set.</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="PREDICT.processing.SearchCV.GridSearchCVfastr">
<em class="property">class </em><code class="descclassname">PREDICT.processing.SearchCV.</code><code class="descname">GridSearchCVfastr</code><span class="sig-paren">(</span><em>estimator</em>, <em>param_grid</em>, <em>scoring=None</em>, <em>fit_params=None</em>, <em>n_jobs=1</em>, <em>iid=True</em>, <em>refit=True</em>, <em>cv=None</em>, <em>verbose=0</em>, <em>pre_dispatch='2*n_jobs'</em>, <em>error_score='raise'</em>, <em>return_train_score=True</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.GridSearchCVfastr" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#PREDICT.processing.SearchCV.BaseSearchCVfastr" title="PREDICT.processing.SearchCV.BaseSearchCVfastr"><code class="xref py py-class docutils literal"><span class="pre">PREDICT.processing.SearchCV.BaseSearchCVfastr</span></code></a></p>
<p>Exhaustive search over specified parameter values for an estimator.</p>
<p>Important members are fit, predict.</p>
<p>GridSearchCV implements a &#8220;fit&#8221; and a &#8220;score&#8221; method.
It also implements &#8220;predict&#8221;, &#8220;predict_proba&#8221;, &#8220;decision_function&#8221;,
&#8220;transform&#8221; and &#8220;inverse_transform&#8221; if they are implemented in the
estimator used.</p>
<p>The parameters of the estimator used to apply these methods are optimized
by cross-validated grid-search over a parameter grid.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="docutils">
<dt>estimator <span class="classifier-delimiter">:</span> <span class="classifier">estimator object.</span></dt>
<dd>This is assumed to implement the scikit-learn estimator interface.
Either estimator needs to provide a <code class="docutils literal"><span class="pre">score</span></code> function,
or <code class="docutils literal"><span class="pre">scoring</span></code> must be passed.</dd>
<dt>param_grid <span class="classifier-delimiter">:</span> <span class="classifier">dict or list of dictionaries</span></dt>
<dd>Dictionary with parameters names (string) as keys and lists of
parameter settings to try as values, or a list of such
dictionaries, in which case the grids spanned by each dictionary
in the list are explored. This enables searching over any sequence
of parameter settings.</dd>
<dt>scoring <span class="classifier-delimiter">:</span> <span class="classifier">string, callable or None, default=None</span></dt>
<dd>A string (see model evaluation documentation) or
a scorer callable object / function with signature
<code class="docutils literal"><span class="pre">scorer(estimator,</span> <span class="pre">X,</span> <span class="pre">y)</span></code>.
If <code class="docutils literal"><span class="pre">None</span></code>, the <code class="docutils literal"><span class="pre">score</span></code> method of the estimator is used.</dd>
<dt>fit_params <span class="classifier-delimiter">:</span> <span class="classifier">dict, optional</span></dt>
<dd>Parameters to pass to the fit method.</dd>
<dt>n_jobs <span class="classifier-delimiter">:</span> <span class="classifier">int, default=1</span></dt>
<dd>Number of jobs to run in parallel.</dd>
<dt>pre_dispatch <span class="classifier-delimiter">:</span> <span class="classifier">int, or string, optional</span></dt>
<dd><p class="first">Controls the number of jobs that get dispatched during parallel
execution. Reducing this number can be useful to avoid an
explosion of memory consumption when more jobs get dispatched
than CPUs can process. This parameter can be:</p>
<blockquote class="last">
<div><ul class="simple">
<li>None, in which case all the jobs are immediately
created and spawned. Use this for lightweight and
fast-running jobs, to avoid delays due to on-demand
spawning of the jobs</li>
<li>An int, giving the exact number of total jobs that are
spawned</li>
<li>A string, giving an expression as a function of n_jobs,
as in &#8216;2*n_jobs&#8217;</li>
</ul>
</div></blockquote>
</dd>
<dt>iid <span class="classifier-delimiter">:</span> <span class="classifier">boolean, default=True</span></dt>
<dd>If True, the data is assumed to be identically distributed across
the folds, and the loss minimized is the total loss per sample,
and not the mean loss across the folds.</dd>
<dt>cv <span class="classifier-delimiter">:</span> <span class="classifier">int, cross-validation generator or an iterable, optional</span></dt>
<dd><p class="first">Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<blockquote>
<div><ul class="simple">
<li>None, to use the default 3-fold cross validation,</li>
<li>integer, to specify the number of folds in a <cite>(Stratified)KFold</cite>,</li>
<li>An object to be used as a cross-validation generator.</li>
<li>An iterable yielding train, test splits.</li>
</ul>
</div></blockquote>
<p>For integer/None inputs, if the estimator is a classifier and <code class="docutils literal"><span class="pre">y</span></code> is
either binary or multiclass, <code class="xref py py-class docutils literal"><span class="pre">StratifiedKFold</span></code> is used. In all
other cases, <code class="xref py py-class docutils literal"><span class="pre">KFold</span></code> is used.</p>
<p class="last">Refer <span class="xref std std-ref">User Guide</span> for the various
cross-validation strategies that can be used here.</p>
</dd>
<dt>refit <span class="classifier-delimiter">:</span> <span class="classifier">boolean, default=True</span></dt>
<dd>Refit the best estimator with the entire dataset.
If &#8220;False&#8221;, it is impossible to make predictions using
this GridSearchCV instance after fitting.</dd>
<dt>verbose <span class="classifier-delimiter">:</span> <span class="classifier">integer</span></dt>
<dd>Controls the verbosity: the higher, the more messages.</dd>
<dt>error_score <span class="classifier-delimiter">:</span> <span class="classifier">&#8216;raise&#8217; (default) or numeric</span></dt>
<dd>Value to assign to the score if an error occurs in estimator fitting.
If set to &#8216;raise&#8217;, the error is raised. If a numeric value is given,
FitFailedWarning is raised. This parameter does not affect the refit
step, which will always raise the error.</dd>
<dt>return_train_score <span class="classifier-delimiter">:</span> <span class="classifier">boolean, default=True</span></dt>
<dd>If <code class="docutils literal"><span class="pre">'False'</span></code>, the <code class="docutils literal"><span class="pre">cv_results_</span></code> attribute will not include training
scores.</dd>
</dl>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">svm</span><span class="p">,</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">GridSearchCV</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:(</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">),</span> <span class="s1">&#39;C&#39;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">svr</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">svr</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="gp">... </span>                            
<span class="go">GridSearchCV(cv=None, error_score=...,</span>
<span class="go">       estimator=SVC(C=1.0, cache_size=..., class_weight=..., coef0=...,</span>
<span class="go">                     decision_function_shape=None, degree=..., gamma=...,</span>
<span class="go">                     kernel=&#39;rbf&#39;, max_iter=-1, probability=False,</span>
<span class="go">                     random_state=None, shrinking=True, tol=...,</span>
<span class="go">                     verbose=False),</span>
<span class="go">       fit_params={}, iid=..., n_jobs=1,</span>
<span class="go">       param_grid=..., pre_dispatch=..., refit=..., return_train_score=...,</span>
<span class="go">       scoring=..., verbose=...)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">sorted</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">cv_results_</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="gp">... </span>                            
<span class="go">[&#39;mean_fit_time&#39;, &#39;mean_score_time&#39;, &#39;mean_test_score&#39;,...</span>
<span class="go"> &#39;mean_train_score&#39;, &#39;param_C&#39;, &#39;param_kernel&#39;, &#39;params&#39;,...</span>
<span class="go"> &#39;rank_test_score&#39;, &#39;split0_test_score&#39;,...</span>
<span class="go"> &#39;split0_train_score&#39;, &#39;split1_test_score&#39;, &#39;split1_train_score&#39;,...</span>
<span class="go"> &#39;split2_test_score&#39;, &#39;split2_train_score&#39;,...</span>
<span class="go"> &#39;std_fit_time&#39;, &#39;std_score_time&#39;, &#39;std_test_score&#39;, &#39;std_train_score&#39;...]</span>
</pre></div>
</div>
<dl class="docutils">
<dt><a href="#id17"><span class="problematic" id="id18">cv_results_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">dict of numpy (masked) ndarrays</span></dt>
<dd><p class="first">A dict with keys as column headers and values as columns, that can be
imported into a pandas <code class="docutils literal"><span class="pre">DataFrame</span></code>.</p>
<p>For instance the below given table</p>
<table border="1" class="docutils">
<colgroup>
<col width="19%" />
<col width="17%" />
<col width="19%" />
<col width="27%" />
<col width="5%" />
<col width="14%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">param_kernel</th>
<th class="head">param_gamma</th>
<th class="head">param_degree</th>
<th class="head">split0_test_score</th>
<th class="head">...</th>
<th class="head"><a href="#id19"><span class="problematic" id="id20">rank_</span></a>....</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>&#8216;poly&#8217;</td>
<td>&#8211;</td>
<td>2</td>
<td>0.8</td>
<td>...</td>
<td>2</td>
</tr>
<tr class="row-odd"><td>&#8216;poly&#8217;</td>
<td>&#8211;</td>
<td>3</td>
<td>0.7</td>
<td>...</td>
<td>4</td>
</tr>
<tr class="row-even"><td>&#8216;rbf&#8217;</td>
<td>0.1</td>
<td>&#8211;</td>
<td>0.8</td>
<td>...</td>
<td>3</td>
</tr>
<tr class="row-odd"><td>&#8216;rbf&#8217;</td>
<td>0.2</td>
<td>&#8211;</td>
<td>0.9</td>
<td>...</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>will be represented by a <code class="docutils literal"><span class="pre">cv_results_</span></code> dict of:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="s1">&#39;param_kernel&#39;</span><span class="p">:</span> <span class="n">masked_array</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">],</span>
                             <span class="n">mask</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span> <span class="kc">False</span> <span class="kc">False</span> <span class="kc">False</span><span class="p">]</span><span class="o">...</span><span class="p">)</span>
<span class="s1">&#39;param_gamma&#39;</span><span class="p">:</span> <span class="n">masked_array</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="o">--</span> <span class="o">--</span> <span class="mf">0.1</span> <span class="mf">0.2</span><span class="p">],</span>
                            <span class="n">mask</span> <span class="o">=</span> <span class="p">[</span> <span class="kc">True</span>  <span class="kc">True</span> <span class="kc">False</span> <span class="kc">False</span><span class="p">]</span><span class="o">...</span><span class="p">),</span>
<span class="s1">&#39;param_degree&#39;</span><span class="p">:</span> <span class="n">masked_array</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.0</span> <span class="mf">3.0</span> <span class="o">--</span> <span class="o">--</span><span class="p">],</span>
                             <span class="n">mask</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span> <span class="kc">False</span>  <span class="kc">True</span>  <span class="kc">True</span><span class="p">]</span><span class="o">...</span><span class="p">),</span>
<span class="s1">&#39;split0_test_score&#39;</span>  <span class="p">:</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span>
<span class="s1">&#39;split1_test_score&#39;</span>  <span class="p">:</span> <span class="p">[</span><span class="mf">0.82</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.78</span><span class="p">],</span>
<span class="s1">&#39;mean_test_score&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mf">0.81</span><span class="p">,</span> <span class="mf">0.60</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.82</span><span class="p">],</span>
<span class="s1">&#39;std_test_score&#39;</span>     <span class="p">:</span> <span class="p">[</span><span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">],</span>
<span class="s1">&#39;rank_test_score&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="s1">&#39;split0_train_score&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span>
<span class="s1">&#39;split1_train_score&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.82</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span>
<span class="s1">&#39;mean_train_score&#39;</span>   <span class="p">:</span> <span class="p">[</span><span class="mf">0.81</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span>
<span class="s1">&#39;std_train_score&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">],</span>
<span class="s1">&#39;mean_fit_time&#39;</span>      <span class="p">:</span> <span class="p">[</span><span class="mf">0.73</span><span class="p">,</span> <span class="mf">0.63</span><span class="p">,</span> <span class="mf">0.43</span><span class="p">,</span> <span class="mf">0.49</span><span class="p">],</span>
<span class="s1">&#39;std_fit_time&#39;</span>       <span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span>
<span class="s1">&#39;mean_score_time&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mf">0.007</span><span class="p">,</span> <span class="mf">0.06</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">],</span>
<span class="s1">&#39;std_score_time&#39;</span>     <span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.002</span><span class="p">,</span> <span class="mf">0.003</span><span class="p">,</span> <span class="mf">0.005</span><span class="p">],</span>
<span class="s1">&#39;params&#39;</span>             <span class="p">:</span> <span class="p">[{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="s1">&#39;degree&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">},</span> <span class="o">...</span><span class="p">],</span>
<span class="p">}</span>
</pre></div>
</div>
<p>NOTE that the key <code class="docutils literal"><span class="pre">'params'</span></code> is used to store a list of parameter
settings dict for all the parameter candidates.</p>
<p class="last">The <code class="docutils literal"><span class="pre">mean_fit_time</span></code>, <code class="docutils literal"><span class="pre">std_fit_time</span></code>, <code class="docutils literal"><span class="pre">mean_score_time</span></code> and
<code class="docutils literal"><span class="pre">std_score_time</span></code> are all in seconds.</p>
</dd>
<dt><a href="#id21"><span class="problematic" id="id22">best_estimator_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">estimator</span></dt>
<dd>Estimator that was chosen by the search, i.e. estimator
which gave highest score (or smallest loss if specified)
on the left out data. Not available if refit=False.</dd>
<dt><a href="#id23"><span class="problematic" id="id24">best_score_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Score of best_estimator on the left out data.</dd>
<dt><a href="#id25"><span class="problematic" id="id26">best_params_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd>Parameter setting that gave the best results on the hold out data.</dd>
<dt><a href="#id27"><span class="problematic" id="id28">best_index_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first">The index (of the <code class="docutils literal"><span class="pre">cv_results_</span></code> arrays) which corresponds to the best
candidate parameter setting.</p>
<p class="last">The dict at <code class="docutils literal"><span class="pre">search.cv_results_['params'][search.best_index_]</span></code> gives
the parameter setting for the best model, that gives the highest
mean score (<code class="docutils literal"><span class="pre">search.best_score_</span></code>).</p>
</dd>
<dt><a href="#id29"><span class="problematic" id="id30">scorer_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">function</span></dt>
<dd>Scorer function used on the held out data to choose the best
parameters for the model.</dd>
<dt><a href="#id31"><span class="problematic" id="id32">n_splits_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>The number of cross-validation splits (folds/iterations).</dd>
</dl>
<p>The parameters selected are those that maximize the score of the left out
data, unless an explicit score is passed in which case it is used instead.</p>
<p>If <cite>n_jobs</cite> was set to a value higher than one, the data is copied for each
point in the grid (and not <cite>n_jobs</cite> times). This is done for efficiency
reasons if individual jobs take very little time, but may raise errors if
the dataset is large and not enough memory is available.  A workaround in
this case is to set <cite>pre_dispatch</cite>. Then, the memory is copied only
<cite>pre_dispatch</cite> many times. A reasonable value for <cite>pre_dispatch</cite> is <cite>2 *
n_jobs</cite>.</p>
<dl class="docutils">
<dt><code class="xref py py-class docutils literal"><span class="pre">ParameterGrid</span></code>:</dt>
<dd>generates all the combinations of a hyperparameter grid.</dd>
<dt><code class="xref py py-func docutils literal"><span class="pre">sklearn.model_selection.train_test_split()</span></code>:</dt>
<dd>utility function to split the data into a development set usable
for fitting a GridSearchCV instance and an evaluation set for
its final evaluation.</dd>
<dt><code class="xref py py-func docutils literal"><span class="pre">sklearn.metrics.make_scorer()</span></code>:</dt>
<dd>Make a scorer from a performance metric or loss function.</dd>
</dl>
<dl class="method">
<dt id="PREDICT.processing.SearchCV.GridSearchCVfastr.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em>, <em>groups=None</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.GridSearchCVfastr.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Run fit with all sets of parameters.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples, n_features]</span></dt>
<dd>Training vector, where n_samples is the number of samples and
n_features is the number of features.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples] or [n_samples, n_output], optional</span></dt>
<dd>Target relative to X for classification or regression;
None for unsupervised learning.</dd>
<dt>groups <span class="classifier-delimiter">:</span> <span class="classifier">array-like, with shape (n_samples,), optional</span></dt>
<dd>Group labels for the samples used while splitting the dataset into
train/test set.</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="PREDICT.processing.SearchCV.RandomizedSearchCVJoblib">
<em class="property">class </em><code class="descclassname">PREDICT.processing.SearchCV.</code><code class="descname">RandomizedSearchCVJoblib</code><span class="sig-paren">(</span><em>estimator</em>, <em>param_distributions={}</em>, <em>n_iter=10</em>, <em>scoring=None</em>, <em>fit_params=None</em>, <em>n_jobs=1</em>, <em>iid=True</em>, <em>refit=True</em>, <em>cv=None</em>, <em>verbose=0</em>, <em>pre_dispatch='2*n_jobs'</em>, <em>random_state=None</em>, <em>error_score='raise'</em>, <em>return_train_score=True</em>, <em>n_jobspercore=100</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.RandomizedSearchCVJoblib" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#PREDICT.processing.SearchCV.BaseSearchCVJoblib" title="PREDICT.processing.SearchCV.BaseSearchCVJoblib"><code class="xref py py-class docutils literal"><span class="pre">PREDICT.processing.SearchCV.BaseSearchCVJoblib</span></code></a></p>
<p>Randomized search on hyper parameters.</p>
<p>RandomizedSearchCV implements a &#8220;fit&#8221; and a &#8220;score&#8221; method.
It also implements &#8220;predict&#8221;, &#8220;predict_proba&#8221;, &#8220;decision_function&#8221;,
&#8220;transform&#8221; and &#8220;inverse_transform&#8221; if they are implemented in the
estimator used.</p>
<p>The parameters of the estimator used to apply these methods are optimized
by cross-validated search over parameter settings.</p>
<p>In contrast to GridSearchCV, not all parameter values are tried out, but
rather a fixed number of parameter settings is sampled from the specified
distributions. The number of parameter settings that are tried is
given by n_iter.</p>
<p>If all parameters are presented as a list,
sampling without replacement is performed. If at least one parameter
is given as a distribution, sampling with replacement is used.
It is highly recommended to use continuous distributions for continuous
parameters.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="docutils">
<dt>estimator <span class="classifier-delimiter">:</span> <span class="classifier">estimator object.</span></dt>
<dd>A object of that type is instantiated for each grid point.
This is assumed to implement the scikit-learn estimator interface.
Either estimator needs to provide a <code class="docutils literal"><span class="pre">score</span></code> function,
or <code class="docutils literal"><span class="pre">scoring</span></code> must be passed.</dd>
<dt>param_distributions <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd>Dictionary with parameters names (string) as keys and distributions
or lists of parameters to try. Distributions must provide a <code class="docutils literal"><span class="pre">rvs</span></code>
method for sampling (such as those from scipy.stats.distributions).
If a list is given, it is sampled uniformly.</dd>
<dt>n_iter <span class="classifier-delimiter">:</span> <span class="classifier">int, default=10</span></dt>
<dd>Number of parameter settings that are sampled. n_iter trades
off runtime vs quality of the solution.</dd>
<dt>scoring <span class="classifier-delimiter">:</span> <span class="classifier">string, callable or None, default=None</span></dt>
<dd>A string (see model evaluation documentation) or
a scorer callable object / function with signature
<code class="docutils literal"><span class="pre">scorer(estimator,</span> <span class="pre">X,</span> <span class="pre">y)</span></code>.
If <code class="docutils literal"><span class="pre">None</span></code>, the <code class="docutils literal"><span class="pre">score</span></code> method of the estimator is used.</dd>
<dt>fit_params <span class="classifier-delimiter">:</span> <span class="classifier">dict, optional</span></dt>
<dd>Parameters to pass to the fit method.</dd>
<dt>n_jobs <span class="classifier-delimiter">:</span> <span class="classifier">int, default=1</span></dt>
<dd>Number of jobs to run in parallel.</dd>
<dt>pre_dispatch <span class="classifier-delimiter">:</span> <span class="classifier">int, or string, optional</span></dt>
<dd><p class="first">Controls the number of jobs that get dispatched during parallel
execution. Reducing this number can be useful to avoid an
explosion of memory consumption when more jobs get dispatched
than CPUs can process. This parameter can be:</p>
<blockquote class="last">
<div><ul class="simple">
<li>None, in which case all the jobs are immediately
created and spawned. Use this for lightweight and
fast-running jobs, to avoid delays due to on-demand
spawning of the jobs</li>
<li>An int, giving the exact number of total jobs that are
spawned</li>
<li>A string, giving an expression as a function of n_jobs,
as in &#8216;2*n_jobs&#8217;</li>
</ul>
</div></blockquote>
</dd>
<dt>iid <span class="classifier-delimiter">:</span> <span class="classifier">boolean, default=True</span></dt>
<dd>If True, the data is assumed to be identically distributed across
the folds, and the loss minimized is the total loss per sample,
and not the mean loss across the folds.</dd>
<dt>cv <span class="classifier-delimiter">:</span> <span class="classifier">int, cross-validation generator or an iterable, optional</span></dt>
<dd><p class="first">Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<blockquote>
<div><ul class="simple">
<li>None, to use the default 3-fold cross validation,</li>
<li>integer, to specify the number of folds in a <cite>(Stratified)KFold</cite>,</li>
<li>An object to be used as a cross-validation generator.</li>
<li>An iterable yielding train, test splits.</li>
</ul>
</div></blockquote>
<p>For integer/None inputs, if the estimator is a classifier and <code class="docutils literal"><span class="pre">y</span></code> is
either binary or multiclass, <code class="xref py py-class docutils literal"><span class="pre">StratifiedKFold</span></code> is used. In all
other cases, <code class="xref py py-class docutils literal"><span class="pre">KFold</span></code> is used.</p>
<p class="last">Refer <span class="xref std std-ref">User Guide</span> for the various
cross-validation strategies that can be used here.</p>
</dd>
<dt>refit <span class="classifier-delimiter">:</span> <span class="classifier">boolean, default=True</span></dt>
<dd>Refit the best estimator with the entire dataset.
If &#8220;False&#8221;, it is impossible to make predictions using
this RandomizedSearchCV instance after fitting.</dd>
<dt>verbose <span class="classifier-delimiter">:</span> <span class="classifier">integer</span></dt>
<dd>Controls the verbosity: the higher, the more messages.</dd>
<dt>random_state <span class="classifier-delimiter">:</span> <span class="classifier">int or RandomState</span></dt>
<dd>Pseudo random number generator state used for random uniform sampling
from lists of possible values instead of scipy.stats distributions.</dd>
<dt>error_score <span class="classifier-delimiter">:</span> <span class="classifier">&#8216;raise&#8217; (default) or numeric</span></dt>
<dd>Value to assign to the score if an error occurs in estimator fitting.
If set to &#8216;raise&#8217;, the error is raised. If a numeric value is given,
FitFailedWarning is raised. This parameter does not affect the refit
step, which will always raise the error.</dd>
<dt>return_train_score <span class="classifier-delimiter">:</span> <span class="classifier">boolean, default=True</span></dt>
<dd>If <code class="docutils literal"><span class="pre">'False'</span></code>, the <code class="docutils literal"><span class="pre">cv_results_</span></code> attribute will not include training
scores.</dd>
</dl>
<dl class="docutils">
<dt><a href="#id33"><span class="problematic" id="id34">cv_results_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">dict of numpy (masked) ndarrays</span></dt>
<dd><p class="first">A dict with keys as column headers and values as columns, that can be
imported into a pandas <code class="docutils literal"><span class="pre">DataFrame</span></code>.</p>
<p>For instance the below given table</p>
<table border="1" class="docutils">
<colgroup>
<col width="22%" />
<col width="20%" />
<col width="30%" />
<col width="5%" />
<col width="23%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">param_kernel</th>
<th class="head">param_gamma</th>
<th class="head">split0_test_score</th>
<th class="head">...</th>
<th class="head">rank_test_score</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>&#8216;rbf&#8217;</td>
<td>0.1</td>
<td>0.8</td>
<td>...</td>
<td>2</td>
</tr>
<tr class="row-odd"><td>&#8216;rbf&#8217;</td>
<td>0.2</td>
<td>0.9</td>
<td>...</td>
<td>1</td>
</tr>
<tr class="row-even"><td>&#8216;rbf&#8217;</td>
<td>0.3</td>
<td>0.7</td>
<td>...</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>will be represented by a <code class="docutils literal"><span class="pre">cv_results_</span></code> dict of:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="s1">&#39;param_kernel&#39;</span> <span class="p">:</span> <span class="n">masked_array</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">],</span>
                              <span class="n">mask</span> <span class="o">=</span> <span class="kc">False</span><span class="p">),</span>
<span class="s1">&#39;param_gamma&#39;</span>  <span class="p">:</span> <span class="n">masked_array</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span> <span class="mf">0.2</span> <span class="mf">0.3</span><span class="p">],</span> <span class="n">mask</span> <span class="o">=</span> <span class="kc">False</span><span class="p">),</span>
<span class="s1">&#39;split0_test_score&#39;</span>  <span class="p">:</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span>
<span class="s1">&#39;split1_test_score&#39;</span>  <span class="p">:</span> <span class="p">[</span><span class="mf">0.82</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span>
<span class="s1">&#39;mean_test_score&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mf">0.81</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span>
<span class="s1">&#39;std_test_score&#39;</span>     <span class="p">:</span> <span class="p">[</span><span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="s1">&#39;rank_test_score&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="s1">&#39;split0_train_score&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span>
<span class="s1">&#39;split1_train_score&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.82</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span>
<span class="s1">&#39;mean_train_score&#39;</span>   <span class="p">:</span> <span class="p">[</span><span class="mf">0.81</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span>
<span class="s1">&#39;std_train_score&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">],</span>
<span class="s1">&#39;mean_fit_time&#39;</span>      <span class="p">:</span> <span class="p">[</span><span class="mf">0.73</span><span class="p">,</span> <span class="mf">0.63</span><span class="p">,</span> <span class="mf">0.43</span><span class="p">,</span> <span class="mf">0.49</span><span class="p">],</span>
<span class="s1">&#39;std_fit_time&#39;</span>       <span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span>
<span class="s1">&#39;mean_score_time&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mf">0.007</span><span class="p">,</span> <span class="mf">0.06</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">],</span>
<span class="s1">&#39;std_score_time&#39;</span>     <span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.002</span><span class="p">,</span> <span class="mf">0.003</span><span class="p">,</span> <span class="mf">0.005</span><span class="p">],</span>
<span class="s1">&#39;params&#39;</span> <span class="p">:</span> <span class="p">[{</span><span class="s1">&#39;kernel&#39;</span> <span class="p">:</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;gamma&#39;</span> <span class="p">:</span> <span class="mf">0.1</span><span class="p">},</span> <span class="o">...</span><span class="p">],</span>
<span class="p">}</span>
</pre></div>
</div>
<p>NOTE that the key <code class="docutils literal"><span class="pre">'params'</span></code> is used to store a list of parameter
settings dict for all the parameter candidates.</p>
<p class="last">The <code class="docutils literal"><span class="pre">mean_fit_time</span></code>, <code class="docutils literal"><span class="pre">std_fit_time</span></code>, <code class="docutils literal"><span class="pre">mean_score_time</span></code> and
<code class="docutils literal"><span class="pre">std_score_time</span></code> are all in seconds.</p>
</dd>
<dt><a href="#id35"><span class="problematic" id="id36">best_estimator_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">estimator</span></dt>
<dd>Estimator that was chosen by the search, i.e. estimator
which gave highest score (or smallest loss if specified)
on the left out data. Not available if refit=False.</dd>
<dt><a href="#id37"><span class="problematic" id="id38">best_score_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Score of best_estimator on the left out data.</dd>
<dt><a href="#id39"><span class="problematic" id="id40">best_params_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd>Parameter setting that gave the best results on the hold out data.</dd>
<dt><a href="#id41"><span class="problematic" id="id42">best_index_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first">The index (of the <code class="docutils literal"><span class="pre">cv_results_</span></code> arrays) which corresponds to the best
candidate parameter setting.</p>
<p class="last">The dict at <code class="docutils literal"><span class="pre">search.cv_results_['params'][search.best_index_]</span></code> gives
the parameter setting for the best model, that gives the highest
mean score (<code class="docutils literal"><span class="pre">search.best_score_</span></code>).</p>
</dd>
<dt><a href="#id43"><span class="problematic" id="id44">scorer_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">function</span></dt>
<dd>Scorer function used on the held out data to choose the best
parameters for the model.</dd>
<dt><a href="#id45"><span class="problematic" id="id46">n_splits_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>The number of cross-validation splits (folds/iterations).</dd>
</dl>
<p>The parameters selected are those that maximize the score of the held-out
data, according to the scoring parameter.</p>
<p>If <cite>n_jobs</cite> was set to a value higher than one, the data is copied for each
parameter setting(and not <cite>n_jobs</cite> times). This is done for efficiency
reasons if individual jobs take very little time, but may raise errors if
the dataset is large and not enough memory is available.  A workaround in
this case is to set <cite>pre_dispatch</cite>. Then, the memory is copied only
<cite>pre_dispatch</cite> many times. A reasonable value for <cite>pre_dispatch</cite> is <cite>2 *
n_jobs</cite>.</p>
<dl class="docutils">
<dt><code class="xref py py-class docutils literal"><span class="pre">GridSearchCV</span></code>:</dt>
<dd>Does exhaustive search over a grid of parameters.</dd>
<dt><code class="xref py py-class docutils literal"><span class="pre">ParameterSampler</span></code>:</dt>
<dd>A generator over parameter settins, constructed from
param_distributions.</dd>
</dl>
<dl class="method">
<dt id="PREDICT.processing.SearchCV.RandomizedSearchCVJoblib.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em>, <em>groups=None</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.RandomizedSearchCVJoblib.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Run fit on the estimator with randomly drawn parameters.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples, n_features]</span></dt>
<dd>Training vector, where n_samples in the number of samples and
n_features is the number of features.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples] or [n_samples, n_output], optional</span></dt>
<dd>Target relative to X for classification or regression;
None for unsupervised learning.</dd>
<dt>groups <span class="classifier-delimiter">:</span> <span class="classifier">array-like, with shape (n_samples,), optional</span></dt>
<dd>Group labels for the samples used while splitting the dataset into
train/test set.</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="PREDICT.processing.SearchCV.RandomizedSearchCVfastr">
<em class="property">class </em><code class="descclassname">PREDICT.processing.SearchCV.</code><code class="descname">RandomizedSearchCVfastr</code><span class="sig-paren">(</span><em>estimator</em>, <em>param_distributions={}</em>, <em>n_iter=10</em>, <em>scoring=None</em>, <em>fit_params=None</em>, <em>n_jobs=1</em>, <em>iid=True</em>, <em>refit=True</em>, <em>cv=None</em>, <em>verbose=0</em>, <em>pre_dispatch='2*n_jobs'</em>, <em>random_state=None</em>, <em>error_score='raise'</em>, <em>return_train_score=True</em>, <em>n_jobspercore=100</em>, <em>fastr_plugin=None</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.RandomizedSearchCVfastr" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#PREDICT.processing.SearchCV.BaseSearchCVfastr" title="PREDICT.processing.SearchCV.BaseSearchCVfastr"><code class="xref py py-class docutils literal"><span class="pre">PREDICT.processing.SearchCV.BaseSearchCVfastr</span></code></a></p>
<p>Randomized search on hyper parameters.</p>
<p>RandomizedSearchCV implements a &#8220;fit&#8221; and a &#8220;score&#8221; method.
It also implements &#8220;predict&#8221;, &#8220;predict_proba&#8221;, &#8220;decision_function&#8221;,
&#8220;transform&#8221; and &#8220;inverse_transform&#8221; if they are implemented in the
estimator used.</p>
<p>The parameters of the estimator used to apply these methods are optimized
by cross-validated search over parameter settings.</p>
<p>In contrast to GridSearchCV, not all parameter values are tried out, but
rather a fixed number of parameter settings is sampled from the specified
distributions. The number of parameter settings that are tried is
given by n_iter.</p>
<p>If all parameters are presented as a list,
sampling without replacement is performed. If at least one parameter
is given as a distribution, sampling with replacement is used.
It is highly recommended to use continuous distributions for continuous
parameters.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="docutils">
<dt>estimator <span class="classifier-delimiter">:</span> <span class="classifier">estimator object.</span></dt>
<dd>A object of that type is instantiated for each grid point.
This is assumed to implement the scikit-learn estimator interface.
Either estimator needs to provide a <code class="docutils literal"><span class="pre">score</span></code> function,
or <code class="docutils literal"><span class="pre">scoring</span></code> must be passed.</dd>
<dt>param_distributions <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd>Dictionary with parameters names (string) as keys and distributions
or lists of parameters to try. Distributions must provide a <code class="docutils literal"><span class="pre">rvs</span></code>
method for sampling (such as those from scipy.stats.distributions).
If a list is given, it is sampled uniformly.</dd>
<dt>n_iter <span class="classifier-delimiter">:</span> <span class="classifier">int, default=10</span></dt>
<dd>Number of parameter settings that are sampled. n_iter trades
off runtime vs quality of the solution.</dd>
<dt>scoring <span class="classifier-delimiter">:</span> <span class="classifier">string, callable or None, default=None</span></dt>
<dd>A string (see model evaluation documentation) or
a scorer callable object / function with signature
<code class="docutils literal"><span class="pre">scorer(estimator,</span> <span class="pre">X,</span> <span class="pre">y)</span></code>.
If <code class="docutils literal"><span class="pre">None</span></code>, the <code class="docutils literal"><span class="pre">score</span></code> method of the estimator is used.</dd>
<dt>fit_params <span class="classifier-delimiter">:</span> <span class="classifier">dict, optional</span></dt>
<dd>Parameters to pass to the fit method.</dd>
<dt>n_jobs <span class="classifier-delimiter">:</span> <span class="classifier">int, default=1</span></dt>
<dd>Number of jobs to run in parallel.</dd>
<dt>pre_dispatch <span class="classifier-delimiter">:</span> <span class="classifier">int, or string, optional</span></dt>
<dd><p class="first">Controls the number of jobs that get dispatched during parallel
execution. Reducing this number can be useful to avoid an
explosion of memory consumption when more jobs get dispatched
than CPUs can process. This parameter can be:</p>
<blockquote class="last">
<div><ul class="simple">
<li>None, in which case all the jobs are immediately
created and spawned. Use this for lightweight and
fast-running jobs, to avoid delays due to on-demand
spawning of the jobs</li>
<li>An int, giving the exact number of total jobs that are
spawned</li>
<li>A string, giving an expression as a function of n_jobs,
as in &#8216;2*n_jobs&#8217;</li>
</ul>
</div></blockquote>
</dd>
<dt>iid <span class="classifier-delimiter">:</span> <span class="classifier">boolean, default=True</span></dt>
<dd>If True, the data is assumed to be identically distributed across
the folds, and the loss minimized is the total loss per sample,
and not the mean loss across the folds.</dd>
<dt>cv <span class="classifier-delimiter">:</span> <span class="classifier">int, cross-validation generator or an iterable, optional</span></dt>
<dd><p class="first">Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<blockquote>
<div><ul class="simple">
<li>None, to use the default 3-fold cross validation,</li>
<li>integer, to specify the number of folds in a <cite>(Stratified)KFold</cite>,</li>
<li>An object to be used as a cross-validation generator.</li>
<li>An iterable yielding train, test splits.</li>
</ul>
</div></blockquote>
<p>For integer/None inputs, if the estimator is a classifier and <code class="docutils literal"><span class="pre">y</span></code> is
either binary or multiclass, <code class="xref py py-class docutils literal"><span class="pre">StratifiedKFold</span></code> is used. In all
other cases, <code class="xref py py-class docutils literal"><span class="pre">KFold</span></code> is used.</p>
<p class="last">Refer <span class="xref std std-ref">User Guide</span> for the various
cross-validation strategies that can be used here.</p>
</dd>
<dt>refit <span class="classifier-delimiter">:</span> <span class="classifier">boolean, default=True</span></dt>
<dd>Refit the best estimator with the entire dataset.
If &#8220;False&#8221;, it is impossible to make predictions using
this RandomizedSearchCV instance after fitting.</dd>
<dt>verbose <span class="classifier-delimiter">:</span> <span class="classifier">integer</span></dt>
<dd>Controls the verbosity: the higher, the more messages.</dd>
<dt>random_state <span class="classifier-delimiter">:</span> <span class="classifier">int or RandomState</span></dt>
<dd>Pseudo random number generator state used for random uniform sampling
from lists of possible values instead of scipy.stats distributions.</dd>
<dt>error_score <span class="classifier-delimiter">:</span> <span class="classifier">&#8216;raise&#8217; (default) or numeric</span></dt>
<dd>Value to assign to the score if an error occurs in estimator fitting.
If set to &#8216;raise&#8217;, the error is raised. If a numeric value is given,
FitFailedWarning is raised. This parameter does not affect the refit
step, which will always raise the error.</dd>
<dt>return_train_score <span class="classifier-delimiter">:</span> <span class="classifier">boolean, default=True</span></dt>
<dd>If <code class="docutils literal"><span class="pre">'False'</span></code>, the <code class="docutils literal"><span class="pre">cv_results_</span></code> attribute will not include training
scores.</dd>
</dl>
<dl class="docutils">
<dt><a href="#id47"><span class="problematic" id="id48">cv_results_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">dict of numpy (masked) ndarrays</span></dt>
<dd><p class="first">A dict with keys as column headers and values as columns, that can be
imported into a pandas <code class="docutils literal"><span class="pre">DataFrame</span></code>.</p>
<p>For instance the below given table</p>
<table border="1" class="docutils">
<colgroup>
<col width="22%" />
<col width="20%" />
<col width="30%" />
<col width="5%" />
<col width="23%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">param_kernel</th>
<th class="head">param_gamma</th>
<th class="head">split0_test_score</th>
<th class="head">...</th>
<th class="head">rank_test_score</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>&#8216;rbf&#8217;</td>
<td>0.1</td>
<td>0.8</td>
<td>...</td>
<td>2</td>
</tr>
<tr class="row-odd"><td>&#8216;rbf&#8217;</td>
<td>0.2</td>
<td>0.9</td>
<td>...</td>
<td>1</td>
</tr>
<tr class="row-even"><td>&#8216;rbf&#8217;</td>
<td>0.3</td>
<td>0.7</td>
<td>...</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>will be represented by a <code class="docutils literal"><span class="pre">cv_results_</span></code> dict of:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="s1">&#39;param_kernel&#39;</span> <span class="p">:</span> <span class="n">masked_array</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">],</span>
                              <span class="n">mask</span> <span class="o">=</span> <span class="kc">False</span><span class="p">),</span>
<span class="s1">&#39;param_gamma&#39;</span>  <span class="p">:</span> <span class="n">masked_array</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span> <span class="mf">0.2</span> <span class="mf">0.3</span><span class="p">],</span> <span class="n">mask</span> <span class="o">=</span> <span class="kc">False</span><span class="p">),</span>
<span class="s1">&#39;split0_test_score&#39;</span>  <span class="p">:</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span>
<span class="s1">&#39;split1_test_score&#39;</span>  <span class="p">:</span> <span class="p">[</span><span class="mf">0.82</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span>
<span class="s1">&#39;mean_test_score&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mf">0.81</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span>
<span class="s1">&#39;std_test_score&#39;</span>     <span class="p">:</span> <span class="p">[</span><span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
<span class="s1">&#39;rank_test_score&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="s1">&#39;split0_train_score&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span>
<span class="s1">&#39;split1_train_score&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.82</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span>
<span class="s1">&#39;mean_train_score&#39;</span>   <span class="p">:</span> <span class="p">[</span><span class="mf">0.81</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span>
<span class="s1">&#39;std_train_score&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">],</span>
<span class="s1">&#39;mean_fit_time&#39;</span>      <span class="p">:</span> <span class="p">[</span><span class="mf">0.73</span><span class="p">,</span> <span class="mf">0.63</span><span class="p">,</span> <span class="mf">0.43</span><span class="p">,</span> <span class="mf">0.49</span><span class="p">],</span>
<span class="s1">&#39;std_fit_time&#39;</span>       <span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span>
<span class="s1">&#39;mean_score_time&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mf">0.007</span><span class="p">,</span> <span class="mf">0.06</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">],</span>
<span class="s1">&#39;std_score_time&#39;</span>     <span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.002</span><span class="p">,</span> <span class="mf">0.003</span><span class="p">,</span> <span class="mf">0.005</span><span class="p">],</span>
<span class="s1">&#39;params&#39;</span> <span class="p">:</span> <span class="p">[{</span><span class="s1">&#39;kernel&#39;</span> <span class="p">:</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;gamma&#39;</span> <span class="p">:</span> <span class="mf">0.1</span><span class="p">},</span> <span class="o">...</span><span class="p">],</span>
<span class="p">}</span>
</pre></div>
</div>
<p>NOTE that the key <code class="docutils literal"><span class="pre">'params'</span></code> is used to store a list of parameter
settings dict for all the parameter candidates.</p>
<p class="last">The <code class="docutils literal"><span class="pre">mean_fit_time</span></code>, <code class="docutils literal"><span class="pre">std_fit_time</span></code>, <code class="docutils literal"><span class="pre">mean_score_time</span></code> and
<code class="docutils literal"><span class="pre">std_score_time</span></code> are all in seconds.</p>
</dd>
<dt><a href="#id49"><span class="problematic" id="id50">best_estimator_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">estimator</span></dt>
<dd>Estimator that was chosen by the search, i.e. estimator
which gave highest score (or smallest loss if specified)
on the left out data. Not available if refit=False.</dd>
<dt><a href="#id51"><span class="problematic" id="id52">best_score_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Score of best_estimator on the left out data.</dd>
<dt><a href="#id53"><span class="problematic" id="id54">best_params_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd>Parameter setting that gave the best results on the hold out data.</dd>
<dt><a href="#id55"><span class="problematic" id="id56">best_index_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first">The index (of the <code class="docutils literal"><span class="pre">cv_results_</span></code> arrays) which corresponds to the best
candidate parameter setting.</p>
<p class="last">The dict at <code class="docutils literal"><span class="pre">search.cv_results_['params'][search.best_index_]</span></code> gives
the parameter setting for the best model, that gives the highest
mean score (<code class="docutils literal"><span class="pre">search.best_score_</span></code>).</p>
</dd>
<dt><a href="#id57"><span class="problematic" id="id58">scorer_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">function</span></dt>
<dd>Scorer function used on the held out data to choose the best
parameters for the model.</dd>
<dt><a href="#id59"><span class="problematic" id="id60">n_splits_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>The number of cross-validation splits (folds/iterations).</dd>
</dl>
<p>The parameters selected are those that maximize the score of the held-out
data, according to the scoring parameter.</p>
<p>If <cite>n_jobs</cite> was set to a value higher than one, the data is copied for each
parameter setting(and not <cite>n_jobs</cite> times). This is done for efficiency
reasons if individual jobs take very little time, but may raise errors if
the dataset is large and not enough memory is available.  A workaround in
this case is to set <cite>pre_dispatch</cite>. Then, the memory is copied only
<cite>pre_dispatch</cite> many times. A reasonable value for <cite>pre_dispatch</cite> is <cite>2 *
n_jobs</cite>.</p>
<dl class="docutils">
<dt><code class="xref py py-class docutils literal"><span class="pre">GridSearchCV</span></code>:</dt>
<dd>Does exhaustive search over a grid of parameters.</dd>
<dt><code class="xref py py-class docutils literal"><span class="pre">ParameterSampler</span></code>:</dt>
<dd>A generator over parameter settings, constructed from
param_distributions.</dd>
</dl>
<dl class="method">
<dt id="PREDICT.processing.SearchCV.RandomizedSearchCVfastr.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em>, <em>groups=None</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.RandomizedSearchCVfastr.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Run fit on the estimator with randomly drawn parameters.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples, n_features]</span></dt>
<dd>Training vector, where n_samples in the number of samples and
n_features is the number of features.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples] or [n_samples, n_output], optional</span></dt>
<dd>Target relative to X for classification or regression;
None for unsupervised learning.</dd>
<dt>groups <span class="classifier-delimiter">:</span> <span class="classifier">array-like, with shape (n_samples,), optional</span></dt>
<dd>Group labels for the samples used while splitting the dataset into
train/test set.</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="PREDICT.processing.SearchCV.chunks">
<code class="descclassname">PREDICT.processing.SearchCV.</code><code class="descname">chunks</code><span class="sig-paren">(</span><em>l</em>, <em>n</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.chunks" title="Permalink to this definition">¶</a></dt>
<dd><p>Yield successive n-sized chunks from l.</p>
</dd></dl>

<dl class="function">
<dt id="PREDICT.processing.SearchCV.chunksdict">
<code class="descclassname">PREDICT.processing.SearchCV.</code><code class="descname">chunksdict</code><span class="sig-paren">(</span><em>data</em>, <em>SIZE</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.chunksdict" title="Permalink to this definition">¶</a></dt>
<dd><p>Split a dictionary in equal parts of certain slice</p>
</dd></dl>

<dl class="function">
<dt id="PREDICT.processing.SearchCV.rms_score">
<code class="descclassname">PREDICT.processing.SearchCV.</code><code class="descname">rms_score</code><span class="sig-paren">(</span><em>truth</em>, <em>prediction</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.rms_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Root-mean-square-error metric</p>
</dd></dl>

<dl class="function">
<dt id="PREDICT.processing.SearchCV.sar_score">
<code class="descclassname">PREDICT.processing.SearchCV.</code><code class="descname">sar_score</code><span class="sig-paren">(</span><em>truth</em>, <em>prediction</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.SearchCV.sar_score" title="Permalink to this definition">¶</a></dt>
<dd><p>SAR metric from Caruana et al. 2004</p>
</dd></dl>

</div>
<div class="section" id="module-PREDICT.processing.fitandscore">
<span id="predict-processing-fitandscore-module"></span><h2>PREDICT.processing.fitandscore module<a class="headerlink" href="#module-PREDICT.processing.fitandscore" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="PREDICT.processing.fitandscore.delete_nonestimator_parameters">
<code class="descclassname">PREDICT.processing.fitandscore.</code><code class="descname">delete_nonestimator_parameters</code><span class="sig-paren">(</span><em>parameters</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.fitandscore.delete_nonestimator_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Delete all parameters in a parameter dictionary that are not used for the
actual estimator.</p>
</dd></dl>

<dl class="function">
<dt id="PREDICT.processing.fitandscore.fit_and_score">
<code class="descclassname">PREDICT.processing.fitandscore.</code><code class="descname">fit_and_score</code><span class="sig-paren">(</span><em>estimator</em>, <em>X</em>, <em>y</em>, <em>scorer</em>, <em>train</em>, <em>test</em>, <em>para</em>, <em>fit_params=None</em>, <em>return_train_score=True</em>, <em>return_n_test_samples=True</em>, <em>return_times=True</em>, <em>return_parameters=True</em>, <em>error_score='raise'</em>, <em>verbose=True</em>, <em>return_all=True</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.fitandscore.fit_and_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit an estimator to a dataset and score the performance. The following
methods can currently be applied as preprocessing before fitting, in
this order:
1. Select features based on feature type group (e.g. shape, histogram).
2. Apply feature imputation (WIP).
3. Apply feature selection based on variance of feature among patients.
4. Univariate statistical testing (e.g. t-test, Wilcoxon).
5. Scale features with e.g. z-scoring.
6. Use Relief feature selection.
7. Select features based on a fit with a LASSO model.
8. Select features using PCA.
9. If a SingleLabel classifier is used for a MultiLabel problem,</p>
<blockquote>
<div>a OneVsRestClassifier is employed around it.</div></blockquote>
<p>All of the steps are optional.</p>
<dl class="docutils">
<dt>estimator: sklearn estimator, mandatory</dt>
<dd>Unfitted estimator which will be fit.</dd>
<dt>X: array, mandatory</dt>
<dd>Array containingfor each object (rows) the feature values
(1st Column) and the associated feature label (2nd Column).</dd>
<dt>y: list(?), mandatory</dt>
<dd>List containing the labels of the objects.</dd>
<dt>scorer: sklearn scorer, mandatory</dt>
<dd>Function used as optimization criterion for the hyperparamater optimization.</dd>
<dt>train: list, mandatory</dt>
<dd>Indices of the objects to be used as training set.</dd>
<dt>test: list, mandatory</dt>
<dd>Indices of the objects to be used as testing set.</dd>
<dt>para: dictionary, mandatory</dt>
<dd>Contains the settings used for the above preprocessing functions
and the fitting. TODO: Create a default object and show the
fields.</dd>
<dt>fit_params:dictionary, default None</dt>
<dd>Parameters supplied to the estimator for fitting. See the SKlearn
site for the parameters of the estimators.</dd>
<dt>return_train_score: boolean, default True</dt>
<dd>Save the training score to the final SearchCV object.</dd>
<dt>return_n_test_samples: boolean, default True</dt>
<dd>Save the number of times each sample was used in the test set
to the final SearchCV object.</dd>
<dt>return_times: boolean, default True</dt>
<dd>Save the time spend for each fit to the final SearchCV object.</dd>
<dt>return_parameters: boolean, default True</dt>
<dd>Return the parameters used in the final fit to the final SearchCV
object.</dd>
<dt>error_score: numeric or &#8220;raise&#8221; by default</dt>
<dd>Value to assign to the score if an error occurs in estimator
fitting. If set to &#8220;raise&#8221;, the error is raised. If a numeric
value is given, FitFailedWarning is raised. This parameter
does not affect the refit step, which will always raise the error.</dd>
<dt>verbose: boolean, default=True</dt>
<dd>If True, print intermediate progress to command line. Warnings are
always printed.</dd>
<dt>return_all: boolean, default=True</dt>
<dd>If False, only the ret object containing the performance will be
returned. If True, the ret object plus all fitted objects will be
returned.</dd>
</dl>
<p>Depending on the return_all input parameter, either only ret or all objects
below are returned.</p>
<dl class="docutils">
<dt>ret: list</dt>
<dd>Contains optionally the train_scores and the test_scores,
test_sample_counts, fit_time, score_time, parameters_est
and parameters_all.</dd>
<dt>GroupSel: PREDICT GroupSel Object</dt>
<dd>Either None if the GroupSelFitted GroupSel Object.</dd>
<dt>VarSel: PREDICT GroupSel Object</dt>
<dd>Either None if the GroupSelFitted GroupSel Object.</dd>
<dt>SelectModel: PREDICT GroupSel Object</dt>
<dd>Either None if the GroupSelFitted GroupSel Object.</dd>
</dl>
<p>feature_labels</p>
<p>scaler</p>
<dl class="docutils">
<dt>imputer: PREDICT GroupSel Object</dt>
<dd>Either None if the GroupSelFitted GroupSel Object.</dd>
<dt>pca: PREDICT GroupSel Object</dt>
<dd>Either None if the GroupSelFitted GroupSel Object.</dd>
<dt>StatisticalSel: PREDICT GroupSel Object</dt>
<dd>Either None if the GroupSelFitted GroupSel Object.</dd>
<dt>ReliefSel: PREDICT GroupSel Object</dt>
<dd>Either None if the GroupSelFitted GroupSel Object.</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="PREDICT.processing.fitandscore.replacenan">
<code class="descclassname">PREDICT.processing.fitandscore.</code><code class="descname">replacenan</code><span class="sig-paren">(</span><em>image_features</em>, <em>verbose=True</em>, <em>feature_labels=None</em><span class="sig-paren">)</span><a class="headerlink" href="#PREDICT.processing.fitandscore.replacenan" title="Permalink to this definition">¶</a></dt>
<dd><p>Replace the NaNs in an image feature matrix.</p>
</dd></dl>

</div>
<div class="section" id="module-PREDICT.processing">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-PREDICT.processing" title="Permalink to this headline">¶</a></h2>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">PREDICT.processing package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-PREDICT.processing.AdvancedSampler">PREDICT.processing.AdvancedSampler module</a></li>
<li><a class="reference internal" href="#module-PREDICT.processing.ICC">PREDICT.processing.ICC module</a></li>
<li><a class="reference internal" href="#module-PREDICT.processing.Imputer">PREDICT.processing.Imputer module</a></li>
<li><a class="reference internal" href="#module-PREDICT.processing.SearchCV">PREDICT.processing.SearchCV module</a></li>
<li><a class="reference internal" href="#module-PREDICT.processing.fitandscore">PREDICT.processing.fitandscore module</a></li>
<li><a class="reference internal" href="#module-PREDICT.processing">Module contents</a></li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/PREDICT.processing.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, Martijn Starmans & Sebastian van der Voort.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.5.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="_sources/PREDICT.processing.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>